py_setup<source>
from pathlib import Path
from copy import deepcopy
import pandas as pd
import rpy2.rinterface
from math import floor
from warnings import filterwarnings
from IPython.display import Image
from random import shuffle
from PIL import Image as PImage
from PIL import ImageDraw, ImageFont
from mmeds.util import load_config, log

filterwarnings('ignore', category=rpy2.rinterface.RRuntimeWarning)

# Load the configuration
config = load_config(Path('config_file.txt').read_text(), Path('metadata.tsv'), True)

# Load metadata file
if '{analysis_type}' == 'qiime2':
    mdf = pd.read_csv('qiime_mapping_file.tsv', skiprows=[1], sep='\t')
else:
    mdf = pd.read_csv('qiime_mapping_file.tsv', sep='\t')
mdf.set_index('#SampleID', inplace=True)

# Load the columns to use for analysis
metadata_columns = sorted(config['metadata'])

# Stores a list of values shared accross groups but unique within (for graphing)
max_colors = 0
max_colors_con = 0
# Create information for R color palettes
for group_name in metadata_columns:
    if not mdf[group_name].isnull().all():
        grouping = mdf[group_name]
        uni = grouping.nunique()
        if config['metadata_continuous'][group_name]:
            # Get the category with the most colors to use for palette creation
            if uni > max_colors_con:
                max_colors_con = uni
        else:
            # Get the category with the most colors to use for palette creation
            if uni > max_colors:
                max_colors = uni

all_colors_con = ['con{{}}'.format(i) for i in range(max_colors_con)]
all_colors = ['color{{}}'.format(i) for i in range(max_colors)]

# Load the extention for jupyter
%load_ext rpy2.ipython
=====
py_setup_2<source>
color_maps = {}
for group_name in metadata_columns:
    if not mdf[group_name].isnull().all():
        grouping = mdf[group_name]
        uni = grouping.nunique() # Unique values in the column
        if config['metadata_continuous'][group_name]:
            inc = floor(max_colors_con / uni) # Increment to advance the color assignments
            color_maps[group_name] = {str(x):'con{}'.format(i * inc)
                                      for i,x in enumerate(grouping.drop_duplicates())}
        else:
            inc = floor(max_colors / uni) # Increment to advance the color assignments
            color_maps[group_name] = {str(x):'color{}'.format(i * inc)
                                      for i, x in enumerate(grouping.drop_duplicates())}
=====
r_setup<source>
%%R -i all_colors -i all_colors_con -o allRGB
library(ggplot2)
library(RColorBrewer)
library(GGally)
library(ggrepel)

# Create custom color palette
myColors <- brewer.pal(11, "Paired")
colorMaker <- colorRampPalette(myColors)
allColorsDisc <- colorMaker(length(unique(all_colors)))
# Custom continuous(ish) color palette
myColorsCon <- brewer.pal(11, "Spectral")
colorMakerCon <- colorRampPalette(myColorsCon)
allColorsCon <- colorMakerCon(length(unique(all_colors_con)))

# Rename the colors to match with the groups
names(allColorsDisc) <- all_colors
names(allColorsCon) <- all_colors_con

# Create the objects for graphing with the colors
allColors <- append(allColorsDisc, allColorsCon)
colScale <- scale_color_manual(name = ~GroupID, values = allColors)
colFill <- scale_fill_manual(name = ~GroupID, values = allColors)

# Rename the colors to match with the groups
# Get the RGB values for the colors
allRGB <- data.frame(apply(data.frame(allColors), 1, col2rgb))
=====
page_break<source>
<div style="page-break-after: always;"></div>
=====
otu_py<source>
df = pd.read_csv('otu_table.tsv', skiprows=1, header=0, sep='\t')
df.set_index('taxonomy', inplace=True)
df.iloc[:5, :5]
=====
taxa_py_qiime1<source>
df = pd.read_csv('{file1}', skiprows=1, sep='\t')
mdf_lite = mdf.reset_index()
mdf_lite = mdf_lite[['#SampleID', '{group}']].rename({{'#SampleID': 'variable'}}, axis='columns')
df = df.rename({{'#OTU ID':'X.OTU.ID'}}, axis='columns').melt(id_vars='X.OTU.ID')
df = df.merge(mdf_lite, how='inner')
df.{group} = df.{group}.astype(str)
# Add colors for plotting
otu_max_colors_{level} = sorted(df['X.OTU.ID'].unique())
=====
taxa_py_qiime2<source>
df = pd.read_csv('{file1}', sep=',')
# Remove unnecessary metadata
headers = list(filter(lambda x: 'k__' in x, df.columns)) + ['index']
df = df.filter(headers).set_index('index').T
# Calculate relative abundances
df = df.apply(lambda x: x / x.sum(), axis='index')
# Transpose the dataframe and convert to long format
df = df.T.reset_index(level=0).melt('index')
# Rename the columns
df.rename({{'index': 'variable', 'variable': 'X.OTU.ID'}}, axis='columns', inplace=True)
# Modify the metadata
mdf_lite = mdf.reset_index()
mdf_lite = mdf_lite[['#SampleID', '{group}']].rename({{'#SampleID': 'variable'}}, axis='columns')
# Merge with the data
df = df.merge(mdf_lite, how='inner')
df.{group} = df.{group}.astype(str)
# Add colors for plotting
otu_max_colors_{level} = sorted(df['X.OTU.ID'].unique())
=====
taxa_color_r<source>
%%R -i otu_max_colors_{level} -o otuAllRGB{level}

# Create custom color palette
otuColors{level} <- brewer.pal(12, "Paired")
otuColorMaker{level} <- colorRampPalette(otuColors{level})
otuAllColors{level} <- otuColorMaker{level}(length(otu_max_colors_{level}))
names(otuAllColors{level}) <- otu_max_colors_{level}
# Create the functions for applying it to plots
otuColScale{level} <- scale_color_manual(name = ~X.OTU.ID, values = otuAllColors{level})
otuColFill{level} <- scale_fill_manual(name = ~X.OTU.ID, values = otuAllColors{level})
# Get the RGB values for the colors
otuAllRGB{level} <- data.frame(apply(data.frame(otuAllColors{level}), 1, col2rgb))
names(otuAllRGB{level}) <- otu_max_colors_{level}
=====
taxa_r<source>
%%R -i df
p <- ggplot(df, aes(x = variable, y = value, fill = X.OTU.ID)) +
     geom_bar(stat = "identity") +
     labs(x = "Sample ID",
          title = 'Taxa Summary',
          subtitle = 'Grouped by {group}') +
     scale_y_discrete(name = "OTU Percentage",
                      limits = c(0, 1),
                      expand = c(0, 0)) +
     theme(text = element_text(size = 8.5,
                               face = "bold"),
           element_line(size = 0.1),
           legend.position = "none",
           axis.text.x = element_text(angle = 300),
           plot.title = element_text(hjust = 0.5),
           plot.subtitle = element_text(hjust = 0.5)) +
     guides(fill = guide_legend(ncol = 4)) +
     facet_grid(~{group}, scales = "free", space = "free") +
     otuColScale{level} + otuColFill{level}

ggsave("{plot}", height = 6, width = 8)
=====
latex_legend_py<source>
with open('mod_revtex.tplx', 'r') as f:
    lines = f.readlines()
for i, line in enumerate(lines):
    if '((* endblock packages *))' in line:
        packages_end = i

for key, value in allRGB.items():
    latex.append('\\definecolor{{{key}}}{{RGB}}{{{r},{g},{b}}}\n'.format(key=key,
                                                                         r=value[1],
                                                                         g=value[2],
                                                                         b=value[3]))

Path('mod_revtex.tplx').write_text('\n'.join(new_lines))
=====
group_legends_py<source>
with open('mod_revtex.tplx', 'r') as f:
    lines = f.readlines()
for i, line in enumerate(lines):
    if '((* endblock packages *))' in line:
        packages_end = i

for group_name, group in df.groupby('GroupName'):
    zipped = zip(group.GroupID.unique(), group.Grouping.unique())
    lists = ['{}/{}'.format(x, y) for x, y in zipped]
    latex.append('\\def\\{group}{{{colors}}}\n'.format(group=group_name, colors=','.join(lists)))

# Remove duplicate values
for row in df:
    new_lines = lines[:packages_end] + latex + lines[packages_end:]

Path('mod_revtex.tplx').write_text('\n'.join(new_lines))
=====
alpha_py_qiime1<source>
# Read in the data
df = pd.read_csv('{file1}', sep='\t')

# Drop unused columns
df.drop('Unnamed: 0', axis=1, inplace=True)
df.drop('iteration', axis=1, inplace=True)

# Set new indeces
df.set_index('sequences per sample', inplace=True)

# Create groupings based on metadata values
group_means = []

for group_name in metadata_columns:
    grouping = mdf[group_name]
    # Calculate the means accross iterations
    groups = df.groupby('sequences per sample')
    means = groups.mean()

    # Join the data and metadata (requires transposing the data)
    joined_means = means.T.join(grouping, how='outer')

    # Group by metadata value and calculate the mean
    grouped_means = joined_means.groupby(group_name)

    # Traspose the data frame again and set the indeces to be a seperate column
    group = grouped_means.mean().T.reset_index(level=0).melt(id_vars='index')
    error = grouped_means.sem().T.reset_index(level=0).melt(id_vars='index')

    # Assign the error values
    group = group.assign(Error=error['value'])

    # Assign information for the colors
    colors = [color_maps[group_name][str(x)] for x in group[group_name]]
    group = group.assign(GroupID=colors)

    # Assign information for groups
    group_names = [group_name for x in group[group_name]]
    group = group.assign(GroupName=group_names)

    # Rename some columns
    new_names = {{
        'index':'SequencesPerSample',
        group_name: 'Grouping',
        'value': 'AverageValue'
    }}
    group = group.rename(index=str, columns=new_names)
    group_means.append(group)

# Stack all the different groups into a single dataframe
df = pd.concat(group_means, axis=0, sort=False)
=====
alpha_py_qiime2<source>
# Read in the data
df = pd.read_csv('{file1}', sep=',')

# Reshape the data into (mostly) long format
headers = list(set(mdf.columns).intersection(set(df.columns)))
df = df.melt(id_vars=['sample-id'] + headers)

# Remove info on specific iterations to allow for grouping by value
replacements = {{x:int(x.split('_')[0].split('-')[1]) for x in df.variable.unique()}}
df.variable.replace(replacements, inplace=True)

# For storing
group_means = []

for group_name in metadata_columns:
    # Remove the metadata not relevant to this grouping
    groups = df[['sample-id', 'variable', 'value', group_name]]

    # Calculate the means accross iterations
    agger = {{'value': 'mean', group_name: 'first'}}
    groups = groups.groupby(['sample-id', 'variable']).agg(agger).reset_index()

    # Add a column to store the errors
    groups = groups.assign(Error=groups.value)

    # Group by metadata value and calculate the means and error
    agger = {{'Error': 'sem', 'value': 'mean'}}
    group = groups.groupby([group_name, 'variable']).agg(agger).reset_index()

    # Assign information for the colors
    colors = [color_maps[group_name][str(x)] for x in group[group_name]]
    group = group.assign(GroupID=colors)

    # Assign information for grouping
    group_names = [group_name for x in group[group_name]]
    group = group.assign(GroupName=group_names)

    # Rename columns and append to the list of dataframes
    new_names = {{
        'variable': 'SamplingDepth',
        'value': 'AverageValue',
         group_name: 'Grouping'
    }}
    group_means.append(group.rename(index=str, columns=new_names))

# Stack all the different groups into a single dataframe
df = pd.concat(group_means, axis=0, sort=False)
df.SamplingDepth = df.SamplingDepth.astype(int)
=====
alpha_r<source>
%%R -i df
pd <- position_dodge(width = 50)

p <- ggplot(data = df, aes(x = {xaxis}, y = AverageValue, color = GroupID)) +
     geom_errorbar(aes(ymin=AverageValue-Error, ymax=AverageValue+Error), width=100, position = pd) +
     geom_point(stat='identity', position = pd, size = 1) +
     geom_line(stat='identity', position = pd) +
     facet_wrap(~GroupName) + colFill + colScale +
     labs(title = 'Alpha Diversity',
          subtitle = 'Grouped by Metadata Catagory') +
     theme_bw() +
     theme(legend.position = 'none',
           plot.title = element_text(hjust = 0.5),
           plot.subtitle = element_text(hjust = 0.5))

# Save plots
ggsave('{file1}', height = 6, width = 6)
=====
beta_py<source>
import pandas as pd
with open('{file1}') as f:
    page = f.read()

store = {{}}
# Parse the PCA information file
for i, line in enumerate(page.split('\n')):
    parts = line.split('\t')
    if i == 0:
        length = int(parts[1])
    if i > 9 :
        if line == '':
            break
        store[parts[0]] = list(map(float, parts[1:length]))

# Create a dataframe and name the axes
df = pd.DataFrame.from_dict(store).T
cols = {{x:'PC{{}}'.format(x + 1) for x in df.columns}}
df = df.rename(index=str, columns=cols)

# Assign GroupIDs based on metadata
samples = mdf['{group}'][df.axes[0]]
df = df.assign(GroupID=[color_maps['{group}'][str(x)] for x in samples])
=====
beta_r<source>
%%R -i df

# Create the plots for the first three PCs
png('{plot}', width = 6, height = 6, unit='in', res=200)
p <- ggpairs(df[,c(1:3)], aes(color = df$GroupID, label = rownames(df), alpha=0.5)) +
         theme_bw() +
         theme(legend.position = 'none',
               plot.title = element_text(hjust = 0.5),
               plot.subtitle = element_text(hjust = 0.5)) +
         labs(title = 'PCA plot',
              subtitle = 'Colored by {cat}')

# Add the color palette to each of the plots
for(i in 1:p$nrow) {{
    for(j in 1:p$ncol){{
        p[i,j] <- p[i,j] + colScale + colFill
    }}
}}
print(p)
out <- dev.off()

# Print the individual PCA plots with labels
for(i in 1:p$nrow) {{
    for(j in 1:p$ncol){{
        # Only print the PCAs not the frequency distributions
        if (i > 2 && j < 3 || i > 1 && j < 2) {{
            # Setup and save each individual PCA plot
            filename <- sprintf('{subplot}',
                                p[i, j]$labels$x,
                                p[i, j]$labels$y)
            png(filename, width = 6, height = 6, unit='in', res=200)
            sp <- p[i,j] + geom_text_repel() +
                      theme(legend.position = 'none',
                            plot.title = element_text(hjust = 0.5),
                            plot.subtitle = element_text(hjust = 0.5)) +
                      labs(title = sprintf('%s vs. %s',
                                           p[i, j]$labels$x,
                                           p[i, j]$labels$y),
                           subtitle = 'Colored by {cat}')
            print(sp)
            out <- dev.off()
        }}
    }}
}}
=====
taxa_caption<source>
The above plot represents the percentage of each sample belonging to particular taxon summarized at level {level}.
=====
alpha_caption_qiime1<source>
Add this
=====
alpha_caption_qiime2<source>
The above plot represents the average value of alpha diversity at each sampling depth. The error bars show the standard error within each group. Groups are determined by the metadata value in each category specified in the plot.
=====
beta_caption<source>
The above plot represents the first three compenents created when performing Principle Component Analysis on the Beta diversity of the samples.
=====
otu_legend_latex<source>
((*- if cell.metadata.{level}: -*))
\vspace{{5mm}}%
{{\raggedright{{}}%
    \texttt{{Color\hspace{{3mm}}Abundance\hspace{{3mm}}OTU}} \\
    \vspace{{3mm}}%
    \foreach \A / \B in \otu{level} {{
        \hspace{{1mm}}\crule[\A]{{5mm}}{{5mm}}\hspace{{5mm}} \texttt{{\B\%\hspace{{8mm}}\A}}\\
    }}
}}%
\vspace{{5mm}}%
((*- endif -*))
=====
otu_group_legend_latex<source>
((*- if cell.metadata.{level}{meta}: -*))
\vspace{{5mm}}%
{{\raggedright{{}}%
    \texttt{{Legend grouped by {meta}}}\\
    \texttt{{Color\hspace{{3mm}}Abundance\hspace{{3mm}}OTU}} \\
    \vspace{{3mm}}%
    \foreach \A / \B in \otu{level}{meta} {{
        \hspace{{1mm}}\crule[\A]{{5mm}}{{5mm}}\hspace{{5mm}} \texttt{{\B\%\hspace{{8mm}}\A}}\\
    }}
}}%
\vspace{{5mm}}%
((*- endif -*))
=====
diversity_legend_latex<source>
((*- if cell.metadata.{meta}: -*))
\vspace{{5mm}}%
{{\raggedright{{}}%
    \texttt{{Legend for {meta}}}\\
    \texttt{{Color\hspace{{3mm}}Metadata}}\\
    \vspace{{3mm}}%
    \foreach \A / \B in \{meta} {{
        \hspace{{1mm}}\crule[\A]{{5mm}}{{5mm}}\hspace{{7mm}}\texttt{{\B}}\\%
    }}
}}%
\vspace{{5mm}}%
((*- endif -*))
=====
otu_group_legend_py<source>

with open('mod_revtex.tplx', 'r') as f:
    lines = f.readlines()
for i, line in enumerate(lines):
    if '((* block packages *))' in line:
        packages_start = i
    elif '((* endblock packages *))' in line:
        packages_end = i
# Filter by abundance
filtered_df = df[df.value > float(config['abundance_threshold'])]

groups = filtered_df.groupby('{meta}')
latex = []
for name, group in groups:
    # Get the means for each group
    means = group.groupby('X.OTU.ID').mean()
    line_latex = []
    for row in means.itertuples():
        perc = 100 * float(row.value)
        # Align sample names
        if perc < 10:
            line_text = '{{}}/ {{:.2f}}'.format(row.Index.replace('_', '\_'), perc)
        else:
            line_text = '{{}}/{{:.2f}}'.format(row.Index.replace('_', '\_'), perc)
        line_latex.append(line_text)
    latex.append('\\def\\{{colorset}}{{{{{{colors}}}}}}\n'.format(colorset='otu{level}{meta}',
                                                          colors=','.join(line_latex)))

new_lines = lines[:packages_end] + latex + lines[packages_end:]

with open('mod_revtex.tplx', 'w') as f:
    for line in new_lines:
        f.write(line)
=====
otu_legend_py<source>
with open('mod_revtex.tplx', 'r') as f:
    lines = f.readlines()
for i, line in enumerate(lines):
    if '((* block packages *))' in line:
        packages_start = i
    elif '((* endblock packages *))' in line:
        packages_end = i


# Get the mean percentage of each taxon
otu_percs = df[df.value > float(config['abundance_threshold'])].groupby('X.OTU.ID').mean()

entries = []
# Remove duplicate values
for row in otu_percs.itertuples():
    otu = row.Index

    # Get the color
    RGB = tuple(otuAllRGB{level}[otu])

    # Align sample names
    perc = 100 * float(otu_percs.loc[otu])
    if perc < 1:
        perc_text = '<0.01'
    elif perc < 10:
        perc_text = ' {{:.2f}}'.format(perc)
    else:
        perc_text = '{{:.2f}}'.format(perc)

    entries.append([otu, RGB, perc_text])


# Create the latex for the legends
latex = []
colors = []
for key, value, perc in entries:
    latex.append('\\definecolor{{{{{{key}}}}}}{{{{RGB}}}}{{{{{{r}},{{g}},{{b}}}}}}\n'.format(key=key.replace('_', '\_'),
                                                                      r=value[0],
                                                                      g=value[1],
                                                                      b=value[2]
                                                                     ))
    colors.append('{{}}/{{}}'.format(key.replace('_', '\_'), perc))


latex.append('\\def\\{{colorset}}{{{{{{colors}}}}}}\n'.format(colorset='otu{level}',
                                                      colors=','.join(colors)))
new_lines = lines[:packages_end] + latex + lines[packages_end:]

with open('mod_revtex.tplx', 'w') as f:
    for line in new_lines:
        f.write(line)
