py_setup<source>
from pathlib import Path
from copy import deepcopy
import pandas as pd
import rpy2.rinterface
from warnings import filterwarnings
from IPython.display import Image
from random import shuffle
from PIL import Image as PImage
from PIL import ImageDraw, ImageFont
from mmeds.util import load_config

filterwarnings('ignore', category=rpy2.rinterface.RRuntimeWarning)

# Load the configuration
config = load_config(Path('config_file.txt').read_text(), Path('metadata.tsv'))

# Set parameters used when making the legend
font_size = int(config['font_size'])
offset = float(font_size) / 2
v_offset = 0
fnt = ImageFont.truetype('{font}', size=font_size)
title_fnt = ImageFont.truetype('{titlefont}', size=int(1.2 * font_size))

# Load metadata file
if '{analysis_type}' == 'qiime2':
    mdf = pd.read_csv('qiime_mapping_file.tsv', skiprows=[1], sep='\t')
else:
    mdf = pd.read_csv('qiime_mapping_file.tsv', sep='\t')
mdf.set_index('#SampleID', inplace=True)

# Load the columns to use for analysis
metadata_columns = sorted(config['metadata'])

# Stores a list of values shared accross groups but unique within (for graphing)
group_ids = []
color_maps = {{}}
max_colors = []
max_colors_con = []
# Create information for R color palettes
for group_name in metadata_columns:
    if not mdf[group_name].isnull().all():
        grouping = mdf[group_name]
        uni = grouping.nunique()
        if config['metadata_continuous'][group_name]:
            group_ids.append(['con' + str(i) for i in range(uni)])
            # Get the category with the most colors to use for palette creation
            if uni > len(max_colors_con):
                max_colors_con = group_ids[-1]
            color_maps[group_name] = {{str(x):'con{{}}'.format(i) for i, x in enumerate(grouping.drop_duplicates())}}
        else:
            group_ids.append(['color' + str(i) for i in range(uni)])
            # Get the category with the most colors to use for palette creation
            if uni > len(max_colors):
                max_colors = group_ids[-1]
            color_maps[group_name] = {{str(x):'color{{}}'.format(i) for i, x in enumerate(grouping.drop_duplicates())}}

# Shuffle the non-continuous colors so values near each other won't be similar shades
shuffle(max_colors, lambda: 0.25)

# Load the extention for jupyter
%load_ext rpy2.ipython
=====
r_setup<source>
%%R -i max_colors -i max_colors_con -o allRGB
library(ggplot2)
library(RColorBrewer)
library(GGally)
library(ggrepel)

# Create custom color palette
myColors <- brewer.pal(12, "Paired")
colorMaker <- colorRampPalette(myColors)
allColorsDisc <- colorMaker(length(unique(max_colors)))
# Custom continuous(ish) color palette
myColorsCon <- brewer.pal(9, "YlOrRd")
colorMakerCon <- colorRampPalette(myColorsCon)
allColorsCon <- colorMakerCon(length(unique(max_colors_con)))

# Rename the colors to match with the groups
names(allColorsDisc) <- max_colors
names(allColorsCon) <- max_colors_con

# Create the objects for graphing with the colors
allColors <- append(allColorsDisc, allColorsCon)
colScale <- scale_color_manual(name = ~GroupID, values = allColors)
colFill <- scale_fill_manual(name = ~GroupID, values = allColors)

# Rename the colors to match with the groups
# Get the RGB values for the colors
allRGB <- data.frame(apply(data.frame(allColors), 1, col2rgb))
=====
page_break<source>
<div style="page-break-after: always;"></div>
=====
otu_py<source>
df = pd.read_csv('otu_table.tsv', skiprows=1, header=0, sep='\t')
df.set_index('taxonomy', inplace=True)
df.iloc[:5, :5]
=====
taxa_py_qiime1<source>
df = pd.read_csv('{file1}', skiprows=1, sep='\t')
mdf_lite = mdf.reset_index()
mdf_lite = mdf_lite[['#SampleID', '{group}']].rename({{'#SampleID': 'variable'}}, axis='columns')
df = df.rename({{'#OTU ID':'X.OTU.ID'}}, axis='columns').melt(id_vars='X.OTU.ID')
df = df.merge(mdf_lite, how='inner')
df.{group} = df.{group}.astype(str)
# Add colors for plotting
otu_max_colors_{level} = sorted(df['X.OTU.ID'].unique())
=====
taxa_py_qiime2<source>
df = pd.read_csv('{file1}', sep=',')
# Remove unnecessary metadata
headers = list(filter(lambda x: 'k__' in x, df.columns)) + ['index']
df = df.filter(headers).set_index('index').T
# Calculate relative abundances
df = df.apply(lambda x: x / x.sum(), axis='index')
# Transpose the dataframe and convert to long format
df = df.T.reset_index(level=0).melt('index')
# Rename the columns
df.rename({{'index': 'variable', 'variable': 'X.OTU.ID'}}, axis='columns', inplace=True)
# Modify the metadata
mdf_lite = mdf.reset_index()
mdf_lite = mdf_lite[['#SampleID', '{group}']].rename({{'#SampleID': 'variable'}}, axis='columns')
# Merge with the data
df = df.merge(mdf_lite, how='inner')
df.{group} = df.{group}.astype(str)
# Add colors for plotting
otu_max_colors_{level} = sorted(df['X.OTU.ID'].unique())
=====
taxa_color_r<source>
%%R -i otu_max_colors_{level} -o otuAllRGB{level}

# Create custom color palette
otuColors{level} <- brewer.pal(12, "Paired")
otuColorMaker{level} <- colorRampPalette(otuColors{level})
otuAllColors{level} <- otuColorMaker{level}(length(otu_max_colors_{level}))
names(otuAllColors{level}) <- otu_max_colors_{level}
# Create the functions for applying it to plots
otuColScale{level} <- scale_color_manual(name = ~X.OTU.ID, values = otuAllColors{level})
otuColFill{level} <- scale_fill_manual(name = ~X.OTU.ID, values = otuAllColors{level})
# Get the RGB values for the colors
otuAllRGB{level} <- data.frame(apply(data.frame(otuAllColors{level}), 1, col2rgb))
names(otuAllRGB{level}) <- otu_max_colors_{level}
=====
taxa_color_py<source>
# Set the height and width based on the number/size of the values to display
height = 60 + 20 * len(otu_max_colors_{level})
width = 80 + 9 * len(max(otu_max_colors_{level}, key=len))

# Create a new image and setup the draw object
im = PImage.new('RGB', (width, height), color='white')
draw = ImageDraw.Draw(im)

# Get the mean percentage of each taxon
otu_percs = df[df.value > float(config['abundance_threshold'])].groupby('X.OTU.ID').mean()

# Add headers
draw.text((0, 0),
          'Color AverageRelativeAbundence OTU',
          fill=(0, 0, 0, 0),
          font=title_fnt)

v_offset += 30
# Remove duplicate values
for row in otu_percs.itertuples():
    otu = row.Index
    # Get the color
    RGB = tuple(otuAllRGB{level}[otu])
    # Draw the color
    draw.rectangle([10, v_offset,
                    30, 20 + v_offset],
                   outline=(0, 0, 0),
                   fill=RGB)

    # Align sample names
    perc = 100 * float(otu_percs.loc[otu])
    if perc < 1:
        line_text = '<0.01% {{}}'.format(otu)
    elif perc < 10:
        line_text = ' {{:.2f}}% {{}}'.format(perc, otu)
    else:
        line_text = '{{:.2f}}% {{}}'.format(perc, otu)
    # Add the metadata value
    draw.text((40, 12 - offset + v_offset),
              line_text,
              fill=(0, 0, 0, 0),
              font=fnt)
    v_offset += 20  # Update offset
del draw

# write to stdout
im.save('taxa_legend_{level}.png', 'PNG')
=====
taxa_group_color_py<source>
# Set parameters used when making the legend
v_offset = 0

# Filter by abundance
filtered_df = df[df.value > float(config['abundance_threshold'])]

# Set the height and width based on the number/size of the values to display
height = ((20 * (filtered_df['{group}'].nunique() - 1)) +
          (20 * filtered_df['X.OTU.ID'].nunique() *
           filtered_df['{group}'].nunique()))
width = 80 + 9 * len(max(filtered_df['X.OTU.ID'], key=len))

# Create a new image and setup the draw object
im = PImage.new('RGB', (width, height), color='white')
draw = ImageDraw.Draw(im)

groups = filtered_df.groupby('{group}')
for name, group in groups:
    # Add the metadata value
    draw.text((40, 12 - offset + v_offset),
              name,
              fill=(0, 0, 0, 0),
              font=title_fnt)
    v_offset += 25  # Update offset
    # Get the means for each group
    means = group.groupby('X.OTU.ID').mean()
    for row in means.itertuples():
        perc = 100 * float(row.value)
        # Align sample names
        if perc < 10:
            line_text = ' {{:.2f}}% {{}}'.format(perc, row.Index)
        else:
            line_text = '{{:.2f}}% {{}}'.format(perc, row.Index)

        # Add the metadata value
        draw.text((40, 10 - offset + v_offset),
                  line_text,
                  fill=(0, 0, 0, 0),
                  font=fnt)
        # Get the color
        RGB = tuple(otuAllRGB{level}[str(row.Index)])
        # Draw the color
        draw.rectangle([10, v_offset,
                        30, 20 + v_offset],
                       outline=(0, 0, 0),
                       fill=RGB)
        v_offset += 20
    v_offset += 5  # Update offset
del draw

# write to stdout
im.save('taxa_{group}_legend_{level}.png', 'PNG')
=====
taxa_r<source>
%%R -i df
p <- ggplot(df, aes(x = variable, y = value, fill = X.OTU.ID)) +
     geom_bar(stat = "identity") +
     labs(x = "Sample ID",
          title = 'Taxa Summary',
          subtitle = 'Grouped by {group}') +
     scale_y_discrete(name = "OTU Percentage",
                      limits = c(0, 1),
                      expand = c(0, 0)) +
     theme(text = element_text(size = 8.5,
                               face = "bold"),
           element_line(size = 0.1),
           legend.position = "none",
           axis.text.x = element_text(angle = 300),
           plot.title = element_text(hjust = 0.5),
           plot.subtitle = element_text(hjust = 0.5)) +
     guides(fill = guide_legend(ncol = 4)) +
     facet_grid(~{group}, scales = "free", space = "free") +
     otuColScale{level} + otuColFill{level}

ggsave("{plot}", height = 6, width = 8)
=====
legend_py<source>
v_offset = 0
height = 0
for group_name in metadata_columns:
    height += 40
    for sample in mdf[group_name].drop_duplicates():
        height += 20

# Create a new image and setup the draw object
im = PImage.new('RGB', (300, height), color='white')
draw = ImageDraw.Draw(im)

for group_name in metadata_columns:
    group = mdf[group_name]
    sub_im = PImage.new('RGB',
                        (300, 40 + (20 * len(group.drop_duplicates()))),
                        color='white')
    sub_draw = ImageDraw.Draw(sub_im)
    # Add the metadata catagory
    draw.text((20, 20 - offset + v_offset),
              str(group_name),
              fill=(0, 0, 0),
              font=fnt)
    sub_draw.text((20, 20 - offset),
                  str(group_name),
                  fill=(0, 0, 0),
                  font=title_fnt)
    sub_offset = 0
    # Remove duplicate values
    for sample in group.sort_values().drop_duplicates():
        v_offset += 20  # Update offset
        sub_offset += 20
        # Get the color
        RGB = tuple(allRGB[color_maps[group_name][str(sample)]])
        # Draw the color
        draw.rectangle([10, 10 + v_offset,
                        30, 30 + v_offset],
                       outline=(0, 0, 0),
                       fill=RGB)
        sub_draw.rectangle([10, 10 + sub_offset,
                            30, 30 + sub_offset],
                           outline=(0, 0, 0),
                           fill=RGB)
        # Add the metadata value
        draw.text((40, 20 - offset + v_offset),
                  str(sample),
                  fill=(0, 0, 0, 0),
                  font=fnt)
        sub_draw.text((40, 20 - offset + sub_offset),
                      str(sample),
                      fill=(0, 0, 0, 0),
                      font=fnt)
    sub_im.save(group_name + '-{legend}', 'PNG')
    v_offset += 30
    del sub_draw
del draw

# write to stdout
im.save('{legend}', 'PNG')
=====
alpha_py_qiime1<source>
# Read in the data
df = pd.read_csv('{file1}', sep='\t')

# Drop unused columns
df.drop('Unnamed: 0', axis=1, inplace=True)
df.drop('iteration', axis=1, inplace=True)

# Set new indeces
df.set_index('sequences per sample', inplace=True)

# Create groupings based on metadata values
group_means = []

for group_name in metadata_columns:
    grouping = mdf[group_name]
    # Calculate the means accross iterations
    groups = df.groupby('sequences per sample')
    means = groups.mean()

    # Join the data and metadata (requires transposing the data)
    joined_means = means.T.join(grouping, how='outer')

    # Group by metadata value and calculate the mean
    grouped_means = joined_means.groupby(group_name)

    # Traspose the data frame again and set the indeces to be a seperate column
    group = grouped_means.mean().T.reset_index(level=0).melt(id_vars='index')
    error = grouped_means.sem().T.reset_index(level=0).melt(id_vars='index')

    # Assign the error values
    group = group.assign(Error=error['value'])

    # Assign information for the colors
    colors = [color_maps[group_name][str(x)] for x in group[group_name]]
    group = group.assign(GroupID=colors)

    # Assign information for groups
    group_names = [group_name for x in group[group_name]]
    group = group.assign(GroupName=group_names)

    # Rename some columns
    new_names = {{
        'index':'SequencesPerSample',
        group_name: 'Grouping',
        'value': 'AverageValue'
    }}
    group = group.rename(index=str, columns=new_names)
    group_means.append(group)

# Stack all the different groups into a single dataframe
df = pd.concat(group_means, axis=0, sort=False)
=====
alpha_py_qiime2<source>
# Read in the data
df = pd.read_csv('{file1}', sep=',')

# Reshape the data into (mostly) long format
headers = list(set(mdf.columns).intersection(set(df.columns)))
df = df.melt(id_vars=['sample-id'] + headers)

# Remove info on specific iterations to allow for grouping by value
replacements = {{x:int(x.split('_')[0].split('-')[1]) for x in df.variable.unique()}}
df.variable.replace(replacements, inplace=True)

# For storing
group_means = []

for group_name in metadata_columns:
    # Remove the metadata not relevant to this grouping
    groups = df[['sample-id', 'variable', 'value', group_name]]

    # Calculate the means accross iterations
    agger = {{'value': 'mean', group_name: 'first'}}
    groups = groups.groupby(['sample-id', 'variable']).agg(agger).reset_index()

    # Add a column to store the errors
    groups = groups.assign(Error=groups.value)

    # Group by metadata value and calculate the means and error
    agger = {{'Error': 'sem', 'value': 'mean'}}
    group = groups.groupby([group_name, 'variable']).agg(agger).reset_index()

    # Assign information for the colors
    colors = [color_maps[group_name][str(x)] for x in group[group_name]]
    group = group.assign(GroupID=colors)

    # Assign information for grouping, drop specific catagories
    group_names = [group_name for x in group[group_name]]
    group = group.assign(GroupName=group_names).drop(group_name, axis='columns')

    # Rename columns and append to the list of dataframes
    new_names = {{
        'variable': 'SamplingDepth',
        'value': 'AverageValue',
         group_name: 'Grouping'
    }}
    group_means.append(group.rename(index=str, columns=new_names))

# Stack all the different groups into a single dataframe
df = pd.concat(group_means, axis=0, sort=False)
df.SamplingDepth = df.SamplingDepth.astype(int)
=====
alpha_r<source>
%%R -i df
pd <- position_dodge(width = 50)

p <- ggplot(data = df, aes(x = {xaxis}, y = AverageValue, color = GroupID)) +
     geom_errorbar(aes(ymin=AverageValue-Error, ymax=AverageValue+Error), width=100, position = pd) +
     geom_point(stat='identity', position = pd, size = 1) +
     geom_line(stat='identity', position = pd) +
     facet_wrap(~GroupName) + colFill + colScale +
     labs(title = 'Alpha Diveristy',
          subtitle = 'Grouped by Metadata Catagory') +
     theme_bw() +
     theme(legend.position = 'none',
           plot.title = element_text(hjust = 0.5),
           plot.subtitle = element_text(hjust = 0.5))

# Save plots
ggsave('{file1}', height = 6, width = 6)
=====
beta_py<source>
import pandas as pd
with open('{file1}') as f:
    page = f.read()

store = {{}}
# Parse the PCA information file
for i, line in enumerate(page.split('\n')):
    parts = line.split('\t')
    if i == 0:
        length = int(parts[1])
    if i > 9 :
        if line == '':
            break
        store[parts[0]] = list(map(float, parts[1:length]))

# Create a dataframe and name the axes
df = pd.DataFrame.from_dict(store).T
cols = {{x:'PC{{}}'.format(x + 1) for x in df.columns}}
df = df.rename(index=str, columns=cols)

# Assign GroupIDs based on metadata
samples = mdf['{group}'][df.axes[0]]
df = df.assign(GroupID=[color_maps['{group}'][str(x)] for x in samples])
=====
beta_r<source>
%%R -i df

# Create the plots for the first three PCs
png('{plot}', width = 6, height = 6, unit='in', res=200)
p <- ggpairs(df[,c(1:3)], aes(color = df$GroupID, label = rownames(df))) +
         theme_bw() +
         theme(legend.position = 'none',
               plot.title = element_text(hjust = 0.5),
               plot.subtitle = element_text(hjust = 0.5)) +
         labs(title = 'PCA plot',
              subtitle = 'Colored by {cat}')

# Add the color palette to each of the plots
for(i in 1:p$nrow) {{
    for(j in 1:p$ncol){{
        p[i,j] <- p[i,j] + colScale + colFill
    }}
}}
print(p)
out <- dev.off()

# Print the individual PCA plots with labels
for(i in 1:p$nrow) {{
    for(j in 1:p$ncol){{
        # Only print the PCAs not the frequency distributions
        if (i > 2 && j < 3 || i > 1 && j < 2) {{
            # Setup and save each individual PCA plot
            filename <- sprintf('{subplot}',
                                p[i, j]$labels$x,
                                p[i, j]$labels$y)
            png(filename, width = 6, height = 6, unit='in', res=200)
            sp <- p[i,j] + geom_text_repel() +
                      theme(legend.position = 'none',
                            plot.title = element_text(hjust = 0.5),
                            plot.subtitle = element_text(hjust = 0.5)) +
                      labs(title = sprintf('%s vs. %s',
                                           p[i, j]$labels$x,
                                           p[i, j]$labels$y),
                           subtitle = 'Colored by {cat}')
            print(sp)
            out <- dev.off()
        }}
    }}
}}
=====
taxa_caption<source>
The above plot represents the percentage of each sample belonging to particular taxon summarized at level {level}.
=====
alpha_caption_qiime1<source>
Add this
=====
alpha_caption_qiime2<source>
The above plot represents the average value of alpha diversity at each sampling depth. The error bars show the standard error within each group. Groups are determined by the metadata value in each category specified in the plot.
=====
beta_caption<source>
The above plot represents the first three compenents created when performing Principle Component Analysis on the Beta diversity of the samples.
